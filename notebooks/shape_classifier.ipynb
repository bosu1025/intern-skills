{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train A Shape Classifier Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "train_data_root = \"../datasets/train\"\n",
    "test_data_root = \"../datasets/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['circle', 'diamond', 'triangle']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations (including resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (black and white images)\n",
    "    transforms.Resize((64, 64)),  # Resize images to 64x64 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images (mean=0.5, std=0.5 for grayscale)\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_data_root, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_root, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Check class names (optional)\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "\n",
    "# 2. Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # ERROR 1 Adjust the right kernel size \n",
    "        # For the CNN model the size of the input and output kernel size should be the same \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: circle, triangle, rectangle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # First Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = F.relu(self.conv2(x))   # Second Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = x.view(x.size(0), -1)   # Flatten\n",
    "        x = F.relu(self.fc1(x))     # Fully Connected Layer 1\n",
    "        x = self.fc2(x)             # Fully Connected Layer 2 (output)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        # ERROR 2\n",
    "        # Get the real accuracy value \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.0899, Accuracy: 37.57%\n",
      "Epoch [2/15], Loss: 0.9999, Accuracy: 49.86%\n",
      "Epoch [3/15], Loss: 0.8635, Accuracy: 59.86%\n",
      "Epoch [4/15], Loss: 0.6583, Accuracy: 73.86%\n",
      "Epoch [5/15], Loss: 0.4424, Accuracy: 82.71%\n",
      "Epoch [6/15], Loss: 0.3126, Accuracy: 88.29%\n",
      "Epoch [7/15], Loss: 0.2063, Accuracy: 93.57%\n",
      "Epoch [8/15], Loss: 0.1487, Accuracy: 95.14%\n",
      "Epoch [9/15], Loss: 0.1020, Accuracy: 97.29%\n",
      "Epoch [10/15], Loss: 0.0674, Accuracy: 98.57%\n",
      "Epoch [11/15], Loss: 0.0367, Accuracy: 99.71%\n",
      "Epoch [12/15], Loss: 0.0245, Accuracy: 99.86%\n",
      "Epoch [13/15], Loss: 0.0194, Accuracy: 99.71%\n",
      "Epoch [14/15], Loss: 0.0106, Accuracy: 100.00%\n",
      "Epoch [15/15], Loss: 0.0065, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Test the mode\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Store the label of the results \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # getting the output using the train model\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Print out the precision, recall and F1 score\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Loss: {running_loss/len(test_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4398669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.6667\n",
      "Test Loss: 0.9777, Accuracy: 74.67%\n",
      "Precision: 0.7611, Recall: 0.7467, F1-score: 0.7522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7610702399861692, 0.7466666666666667, 0.7522413628330257)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Show Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def show_prediction(model, image_path):\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path)  \n",
    "    # Data preprocessing\n",
    "    transformed = transform(image).unsqueeze(0).to(device) \n",
    "\n",
    "    # Predict the output\n",
    "    with torch.no_grad():\n",
    "        output = model(transformed)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probs, 1)\n",
    "    # Visualize the result \n",
    "    plt.imshow(image.convert(\"L\"), cmap='gray')\n",
    "    # Comparing the predicted shape and the actual shape\n",
    "    plt.title(f\"Prediction: {train_dataset.classes[predicted.item()]} ({confidence.item()*100:.1f}%)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c68552dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting the output \n",
    "show_prediction(model,'../datasets/test/circle/circle_3.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
